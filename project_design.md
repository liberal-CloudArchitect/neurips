# 项目设计方案：NeurIPS 2025 聚合物性质预测

## 1. 目标

本方案旨在为“NeurIPS 2025 公开聚合物预测竞赛”设计一个全面、高效且可扩展的机器学习工作流。目标是构建一个能够根据SMILES字符串准确预测五种聚合物物理性质的模型，并在排行榜上取得优异成绩。

## 2. 数据预处理与表示

输入数据是SMILES字符串，必须将其转换为适合机器学习模型的数值表示。我们将探索并可能结合以下几种表示方法：

### 2.1. 基线表示：分子指纹
- **方法**: 使用 `RDKit` 库生成多种分子指纹的组合。
- **流程**: 
    1.  将每个SMILES字符串解析为 `RDKit` 的分子对象。
    2.  计算多种分子指纹：
        - **Morgan指纹** (2048位): 扩展连通性指纹，捕获局部结构模式
        - **MACCS分子密钥** (167位): 预定义的化学子结构模式，广泛验证的特征集
    3.  特征融合：将不同指纹横向拼接形成组合特征向量
- **优点**: 
    - Morgan指纹：计算速度快，覆盖面广
    - MACCS Keys：特征解释性强，在药物发现中验证有效
    - 组合使用：优势互补，提供更全面的分子表示

### 2.2. 图表示 (用于GNN)
- **方法**: 将每个SMILES字符串转换为一个图结构。
- **流程**:
    1.  **节点 (Nodes)**: 图中的每个节点代表一个原子。
    2.  **节点特征 (Node Features)**: 每个节点的特征向量可以包括：
        - 原子类型 (如 C, O, N)，进行 one-hot 编码。
        - 原子在环中的度、总度。
        - 形式电荷、杂化方式。
        - 是否为芳香原子。
    3.  **边 (Edges)**: 图中的每条边代表一个化学键。
    4.  **边特征 (Edge Features)**: 每条边的特征向量可以包括：
        - 化学键类型（单键、双键、三键、芳香键），进行 one-hot 编码。
        - 是否在环中。
- **工具**: 使用 `PyTorch Geometric` 或 `DGL` 库来方便地构建和处理分子图。

### 2.3. 序列表示 (用于Transformer)
- **方法**: 将SMILES字符串视为一个语言序列。
- **流程**:
    1.  **分词 (Tokenization)**: 构建一个词汇表，将SMILES字符串分解为一系列的token（例如，单个原子 `C`, `O`, `N`，或者特殊字符 `(`, `)`, `[` 等）。
    2.  **编码 (Encoding)**: 将每个token映射到一个整数索引。
    3.  **填充 (Padding)**: 将所有序列填充到相同的长度。

## 3. 特征工程

除了端到端的学习，我们还将计算一些全局分子描述符作为辅助特征，与深度学习模型的输出拼接或共同输入。

- **计算**: 使用 `RDKit` 计算以下描述符：
    - 分子量 (Molecular Weight)
    - 极性表面积 (Topological Polar Surface Area, TPSA)
    - 脂水分配系数 (LogP)
    - 氢键供体和受体数量
    - 可旋转键数量

## 4. 模型架构

我们将从一个简单的基线模型开始，逐步迭代到更复杂的深度学习模型。

### 4.1. 基线模型
- **模型**: **XGBoost** 或 **LightGBM**。
- **输入**: Morgan指纹 + 计算出的分子描述符。
- **目的**: 快速验证数据处理流程，并为后续模型提供一个性能比较的基准。

### 4.2. 主力模型 1：图神经网络 (GNN)
- **模型**: **Graph Attention Network (GAT)** 或 **Message Passing Neural Network (MPNN)**。
- **架构**:
    1.  输入层：接收 `PyTorch Geometric` 格式的图数据。
    2.  图卷积层：堆叠多层GNN层来学习节点（原子）的表示。
    3.  池化层：使用全局注意力池化或均值池化，将所有节点的表示聚合为单个图级别的向量。
    4.  输出层：一个多层感知机（MLP），接收图向量，并输出5个目标性质的预测值。

### 4.3. 主力模型 2：Transformer
- **模型**: 基于 **BERT** 架构的 **SMILES Transformer**。
- **架构**:
    1.  **微调 (Fine-tuning)**: 加载一个在大型化学数据库上预训练好的模型（如 `ChemBERTa`）。
    2.  **分类头 (Classification Head)**: 将预训练模型的 `[CLS]` token 输出连接到一个新的MLP头，该MLP头被训练用于预测我们的5个目标性质。
    - **从头训练 (From Scratch)**: 如果微调效果不佳或为了实验，我们可以构建一个较小的Transformer编码器，在我们的训练数据上从头开始训练。
- **实施要点**: 由于竞赛环境无网络，无法从Hugging Face Hub动态下载模型。我们必须提前将 `ChemBERTa` 模型文件上传到Kaggle，并创建一个私有的Kaggle数据集。在代码中，我们将从这个数据集加载模型。

### 4.4. 集成学习 (Ensembling)
- **策略**: 在后期，我们将对GNN和Transformer模型的预测结果进行加权平均或使用一个简单的线性模型进行堆叠（Stacking），以期获得更稳定和精确的最终预测。

## 5. 损失函数与优化

### 5.1. 损失函数选择
- **主要损失函数**: **平滑L1损失 (Smooth L1 Loss / Huber Loss)**，对异常值更鲁棒
- **备选方案**: 
    - **均方误差 (MSE)**: 适合没有严重异常值的情况
    - **平均绝对误差 (MAE)**: 与评估指标一致，但梯度不连续
- **多任务学习**: 使用加权损失函数，为不同性质分配不同权重

### 5.2. 超参数搜索空间
- **学习率**: [1e-5, 1e-2] (对数尺度)
- **批次大小**: [16, 32, 64, 128]
- **Dropout率**: [0.1, 0.2, 0.3, 0.5]
- **网络层数**: [2, 3, 4, 6]层
- **隐藏维度**: [128, 256, 512, 1024]

## 6. 数据增强策略

### 6.1. SMILES数据增强
- **随机SMILES**: 生成化学等价但表示不同的SMILES字符串
- **原子排列增强**: 改变SMILES中原子的访问顺序
- **分子旋转**: 对于支持3D结构的表示方法

### 6.2. 噪声注入
- **特征噪声**: 在分子描述符中添加小量高斯噪声
- **Dropout增强**: 训练时随机丢弃部分原子或键特征

## 7. 验证策略

- **方法**: **K-折交叉验证 (K-Fold Cross-Validation)**，例如 K=5 或 K=10。
- **流程**:
    1.  将训练数据分成K个不相交的子集。
    2.  进行K次训练-验证循环，每次使用K-1个子集进行训练，剩下的1个子集进行验证。
    3.  本地的最终性能评估将是K次验证结果的平均值。
- **目的**: 确保模型性能的稳健性，避免在公共排行榜上过拟合。

## 8. 模型解释性

### 8.1. 注意力可视化
- **GNN模型**: 可视化原子和键的注意力权重
- **Transformer模型**: 分析SMILES token的注意力分布

### 8.2. 特征重要性分析
- **SHAP值**: 分析每个分子描述符的贡献
- **梯度分析**: 了解哪些结构特征对预测最重要

## 9. 硬件要求与性能优化

### 9.1. 硬件配置
- **本地开发配置**:
    - **推荐配置**: 
        - GPU: NVIDIA RTX 4090 或 A100 (24GB+ VRAM)
        - CPU: 16+ 核心
        - 内存: 64GB+ RAM
        - 存储: 1TB+ SSD
    - **最低配置**: 
        - GPU: NVIDIA GTX 1080Ti (11GB VRAM)
        - CPU: 8+ 核心
        - 内存: 32GB RAM
- **Kaggle提交环境**:
    - **注意**: 最终代码将在Kaggle提供的标准环境中运行，通常是配备了NVIDIA T4或P100 GPU的虚拟机。我们的模型设计（特别是内存占用）必须与此兼容。

### 9.2. 性能优化策略
- **混合精度训练**: 使用FP16减少显存占用
- **梯度累积**: 在小批次上模拟大批次训练
- **模型并行**: 对于大型Transformer模型
- **数据并行**: 多GPU训练加速

## 10. 软件与库

- **核心库**: `Python 3.10+`
- **化学信息学**: `rdkit-pypi`
- **数据处理**: `pandas`, `numpy`, `scikit-learn`
- **机器学习**: `xgboost`, `lightgbm`, `optuna` (超参数优化)
- **深度学习**: `pytorch`, `pytorch-geometric` (for GNNs), `transformers` (for Hugging Face models)
- **可视化**: `matplotlib`, `seaborn`, `plotly`
- **实验管理**: `wandb` 或 `mlflow`
  - **注意**: 这些工具非常适合在本地进行实验跟踪。但在最终提交的Notebook中，必须禁用它们的在线同步功能（例如，通过设置 `WANDB_MODE=disabled`），以遵守无网络规则，否则会导致代码执行失败。
- **环境管理**: `conda` 或 `venv`